import logging

from airflow.providers.amazon.aws.hooks.s3 import S3Hook
from airflow.sdk import dag, task
import pendulum


@dag(
    dag_id="test_minio_conn",
    schedule=None,
    start_date=pendulum.datetime(2025, 1, 1),
    catchup=False,
    default_args={
        "owner": "jungeun_park",
    },
    tags=["test", "minio", "connection"],
    description="MinIO ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ DAG",
)
def simple_minio_conn_test():
    """
    Airflowì˜ S3Hookì„ ì‚¬ìš©í•˜ì—¬ MinIO ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•˜ê³ ,
    ë²„í‚· ëª©ë¡ì„ ì¡°íšŒí•˜ëŠ” DAG
    """

    @task
    def test_minio_connection():
        logger = logging.getLogger(__name__)

        logger.info("ğŸ” MinIO ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. (minio_conn ì‚¬ìš©)")

        # 1) S3Hook ì´ˆê¸°í™”
        # ì´ Hookì€ Airflow UIì— ì„¤ì •ëœ 'minio_conn' ì •ë³´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        hook = S3Hook(aws_conn_id="minio_conn")

        # 2) Boto3 í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œ í†µì‹  ê°ì²´)
        # ì´ ì‹œì ì—ì„œ MinIO ì„œë²„ë¡œ ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤.
        client = hook.get_conn()

        try:
            # 3) ë²„í‚· ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸ (ê°€ì¥ ê°„ë‹¨í•œ S3 API í˜¸ì¶œ)
            buckets_response = client.list_buckets()

            logger.info("=========================================")
            logger.info("âœ… ì—°ê²° ì„±ê³µ! ë²„í‚· ëª©ë¡ì„ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.")
            logger.info("=========================================")

            # ì¡°íšŒëœ ë²„í‚· ì´ë¦„ì„ ì¶œë ¥
            bucket_names = [b["Name"] for b in buckets_response.get("Buckets", [])]
            logger.info("í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë²„í‚·: %s", bucket_names)

        except Exception:
            logger.exception("=========================================")
            logger.exception("âŒ ì—°ê²° ì‹¤íŒ¨ ë˜ëŠ” API í˜¸ì¶œ ì˜¤ë¥˜ ë°œìƒ")
            logger.exception("=========================================")
            raise

        return "Connection Test OK"

    test_minio_connection()


simple_minio_conn_test()
